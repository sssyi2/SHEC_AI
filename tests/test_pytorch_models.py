# PyTorchæ¨¡å‹ç»“æ„æµ‹è¯•è„šæœ¬
# éªŒè¯æ¨¡å‹åˆ›å»ºã€å‰å‘ä¼ æ’­å’ŒåŸºæœ¬åŠŸèƒ½

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import numpy as np
from models.model_factory import ModelFactory, model_manager
from models.health_lstm import HealthLSTM, MultiTaskHealthLSTM
from models.risk_assessment import RiskAssessmentNet, MultiDiseaseRiskNet
from utils.logger import get_logger

logger = get_logger(__name__)

def test_health_lstm():
    """æµ‹è¯•HealthLSTMæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• HealthLSTM æ¨¡å‹")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = ModelFactory.create_health_lstm(
            input_dim=20,
            hidden_dim=64,
            num_layers=2,
            output_dim=3,
            sequence_length=7,
            dropout=0.1
        )
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model.__class__.__name__}")
        print(f"âœ“ è®¾å¤‡: {model.device}")
        print(f"âœ“ æ¨¡å‹ä¿¡æ¯: {model.get_model_info()}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        sequence_length = 7
        input_dim = 20
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_input = torch.randn(batch_size, sequence_length, input_dim)
        
        print(f"\næµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        # ç§»åŠ¨æ•°æ®åˆ°åŒä¸€è®¾å¤‡
        test_input = test_input.to(model.device)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            output = model(test_input)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æµ‹è¯•é¢„æµ‹åŠŸèƒ½
        test_data = np.random.randn(sequence_length, input_dim)
        prediction = model.predict(test_data)
        print(f"âœ“ é¢„æµ‹åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼Œé¢„æµ‹ç»“æœå½¢çŠ¶: {prediction.shape}")
        
        # æµ‹è¯•åºåˆ—é¢„æµ‹
        sequence_pred = model.predict_sequence(test_data, future_steps=3)
        print(f"âœ“ åºåˆ—é¢„æµ‹åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼Œé¢„æµ‹åºåˆ—å½¢çŠ¶: {sequence_pred.shape}")
        
        print("âœ“ HealthLSTM æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— HealthLSTM æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_risk_assessment():
    """æµ‹è¯•RiskAssessmentNetæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• RiskAssessmentNet æ¨¡å‹")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = ModelFactory.create_risk_assessment(
            input_dim=25,
            hidden_dims=[128, 64, 32],
            num_classes=3,
            dropout=0.2
        )
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model.__class__.__name__}")
        print(f"âœ“ è®¾å¤‡: {model.device}")
        print(f"âœ“ æ¨¡å‹ä¿¡æ¯: {model.get_model_info()}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 8
        input_dim = 25
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_input = torch.randn(batch_size, input_dim)
        
        print(f"\næµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        # ç§»åŠ¨æ•°æ®åˆ°åŒä¸€è®¾å¤‡
        test_input = test_input.to(model.device)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            outputs = model(test_input)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
            for key, value in outputs.items():
                print(f"  - {key}: {value.shape}")
        
        # æµ‹è¯•é£é™©é¢„æµ‹åŠŸèƒ½
        test_data = np.random.randn(input_dim)
        risk_result = model.predict_risk(test_data)
        print(f"âœ“ é£é™©é¢„æµ‹åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        for key, value in risk_result.items():
            if isinstance(value, np.ndarray):
                print(f"  - {key}: å½¢çŠ¶ {value.shape}")
            else:
                print(f"  - {key}: {value}")
        
        # æµ‹è¯•ç‰¹å¾é‡è¦æ€§
        importance = model.get_feature_importance(test_data)
        print(f"âœ“ ç‰¹å¾é‡è¦æ€§åˆ†ææˆåŠŸï¼Œå½¢çŠ¶: {importance.shape}")
        
        print("âœ“ RiskAssessmentNet æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— RiskAssessmentNet æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_multitask_lstm():
    """æµ‹è¯•MultiTaskHealthLSTMæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• MultiTaskHealthLSTM æ¨¡å‹")
    print("=" * 60)
    
    try:
        # ä»»åŠ¡é…ç½®
        task_configs = {
            'blood_pressure': {'output_dim': 2},  # æ”¶ç¼©å‹ã€èˆ’å¼ å‹
            'blood_sugar': {'output_dim': 1},     # è¡€ç³–å€¼
            'heart_rate': {'output_dim': 1},      # å¿ƒç‡
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = ModelFactory.create_multitask_lstm(
            input_dim=30,
            task_configs=task_configs,
            shared_hidden_dim=128
        )
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model.__class__.__name__}")
        print(f"âœ“ è®¾å¤‡: {model.device}")
        print(f"âœ“ ä»»åŠ¡æ•°é‡: {len(task_configs)}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        sequence_length = 7
        input_dim = 30
        
        test_input = torch.randn(batch_size, sequence_length, input_dim)
        print(f"\næµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        # ç§»åŠ¨æ•°æ®åˆ°åŒä¸€è®¾å¤‡
        test_input = test_input.to(model.device)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            outputs = model(test_input)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
            for task_name, output in outputs.items():
                print(f"  - {task_name}: {output.shape}")
        
        # æµ‹è¯•å¤šä»»åŠ¡é¢„æµ‹
        test_data = np.random.randn(sequence_length, input_dim)
        predictions = model.predict_multi_task(test_data)
        print(f"âœ“ å¤šä»»åŠ¡é¢„æµ‹åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        for task_name, pred in predictions.items():
            print(f"  - {task_name}: å½¢çŠ¶ {pred.shape}")
        
        print("âœ“ MultiTaskHealthLSTM æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— MultiTaskHealthLSTM æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_multidisease_risk():
    """æµ‹è¯•MultiDiseaseRiskNetæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• MultiDiseaseRiskNet æ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç–¾ç—…é…ç½®
        disease_configs = {
            'diabetes': {'num_classes': 2, 'weight': 1.0},      # ç³–å°¿ç—…ï¼šæœ‰/æ— 
            'hypertension': {'num_classes': 3, 'weight': 1.2},  # é«˜è¡€å‹ï¼šæ­£å¸¸/è½»åº¦/é‡åº¦
            'heart_disease': {'num_classes': 2, 'weight': 1.5}, # å¿ƒè„ç—…ï¼šæœ‰/æ— 
        }
        
        # åˆ›å»ºæ¨¡å‹
        model = ModelFactory.create_model('multidisease_risk', {
            'input_dim': 35,
            'disease_configs': disease_configs,
            'shared_hidden_dims': [256, 128],
            'dropout': 0.3
        })
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {model.__class__.__name__}")
        print(f"âœ“ è®¾å¤‡: {model.device}")
        print(f"âœ“ ç–¾ç—…æ•°é‡: {len(disease_configs)}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 6
        input_dim = 35
        
        test_input = torch.randn(batch_size, input_dim)
        print(f"\næµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        
        # ç§»åŠ¨æ•°æ®åˆ°åŒä¸€è®¾å¤‡
        test_input = test_input.to(model.device)
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            outputs = model(test_input)
            print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
            for key, value in outputs.items():
                print(f"  - {key}: {value.shape}")
        
        # æµ‹è¯•å¤šç–¾ç—…é£é™©é¢„æµ‹
        test_data = np.random.randn(input_dim)
        risk_results = model.predict_multi_disease_risk(test_data)
        print(f"âœ“ å¤šç–¾ç—…é£é™©é¢„æµ‹åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        for disease, result in risk_results.items():
            if disease == 'global_risk_score':
                print(f"  - {disease}: {result}")
            else:
                print(f"  - {disease}:")
                for key, value in result.items():
                    if isinstance(value, np.ndarray):
                        print(f"    * {key}: å½¢çŠ¶ {value.shape}")
                    else:
                        print(f"    * {key}: {value}")
        
        print("âœ“ MultiDiseaseRiskNet æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— MultiDiseaseRiskNet æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_management():
    """æµ‹è¯•æ¨¡å‹ç®¡ç†åŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•æ¨¡å‹ç®¡ç†åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹
        model = ModelFactory.create_health_lstm(
            input_dim=15,
            hidden_dim=32,
            output_dim=1
        )
        
        print(f"âœ“ æµ‹è¯•æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # ä¿å­˜æ¨¡å‹
        model_name = "test_health_lstm"
        version = "v1.0.0"
        
        saved_path = model_manager.save_model(
            model=model,
            model_name=model_name,
            version=version,
            metadata={'description': 'æµ‹è¯•ç”¨LSTMæ¨¡å‹', 'accuracy': 0.95}
        )
        
        print(f"âœ“ æ¨¡å‹ä¿å­˜æˆåŠŸ: {saved_path}")
        
        # åˆ—å‡ºæ¨¡å‹
        models_list = model_manager.list_models()
        print(f"âœ“ æ¨¡å‹åˆ—è¡¨: {models_list}")
        
        # åŠ è½½æ¨¡å‹
        loaded_model, metadata = model_manager.load_model(model_name, version)
        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {loaded_model.__class__.__name__}")
        print(f"âœ“ å…ƒæ•°æ®: {metadata['version']}")
        
        # æµ‹è¯•åŠ è½½çš„æ¨¡å‹
        test_input = torch.randn(1, 7, 15)
        test_input = test_input.to(loaded_model.device)  # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        with torch.no_grad():
            output = loaded_model(test_input)
            print(f"âœ“ åŠ è½½çš„æ¨¡å‹å·¥ä½œæ­£å¸¸ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = model_manager.get_model_info(model_name, version)
        print(f"âœ“ æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ")
        
        # æ¸…ç†æµ‹è¯•æ¨¡å‹
        model_manager.delete_model(model_name)
        print(f"âœ“ æµ‹è¯•æ¨¡å‹åˆ é™¤æˆåŠŸ")
        
        print("âœ“ æ¨¡å‹ç®¡ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹ç®¡ç†åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_gpu_compatibility():
    """æµ‹è¯•GPUå…¼å®¹æ€§"""
    print("=" * 60)
    print("æµ‹è¯•GPUå…¼å®¹æ€§")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        cuda_available = torch.cuda.is_available()
        print(f"CUDA å¯ç”¨: {cuda_available}")
        
        if cuda_available:
            gpu_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            device_name = torch.cuda.get_device_name(current_device)
            
            print(f"GPU æ•°é‡: {gpu_count}")
            print(f"å½“å‰è®¾å¤‡: {current_device}")
            print(f"è®¾å¤‡åç§°: {device_name}")
            
            # æµ‹è¯•GPUä¸Šçš„æ¨¡å‹
            model = ModelFactory.create_risk_assessment(
                input_dim=20,
                device='cuda'
            )
            
            print(f"âœ“ GPUæ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {model.device}")
            
            # åœ¨GPUä¸Šæµ‹è¯•
            test_input = torch.randn(4, 20).cuda()
            with torch.no_grad():
                output = model(test_input)
                print(f"âœ“ GPUå‰å‘ä¼ æ’­æˆåŠŸ")
            
        else:
            print("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
            model = ModelFactory.create_risk_assessment(
                input_dim=20,
                device='cpu'
            )
            print(f"âœ“ CPUæ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {model.device}")
        
        print("âœ“ GPUå…¼å®¹æ€§æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— GPUå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹PyTorchæ¨¡å‹ç»“æ„æµ‹è¯•")
    print("=" * 80)
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("HealthLSTMæ¨¡å‹", test_health_lstm),
        ("RiskAssessmentNetæ¨¡å‹", test_risk_assessment),
        ("MultiTaskHealthLSTMæ¨¡å‹", test_multitask_lstm),
        ("MultiDiseaseRiskNetæ¨¡å‹", test_multidisease_risk),
        ("æ¨¡å‹ç®¡ç†åŠŸèƒ½", test_model_management),
        ("GPUå…¼å®¹æ€§", test_gpu_compatibility),
    ]
    
    for test_name, test_func in tests:
        print(f"\nå¼€å§‹æµ‹è¯•: {test_name}")
        result = test_func()
        test_results.append((test_name, result))
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "é€šè¿‡" if result else "å¤±è´¥"
        symbol = "âœ“" if result else "âœ—"
        print(f"{symbol} {test_name}: {status}")
        
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\næ€»è®¡: {passed + failed} ä¸ªæµ‹è¯•")
    print(f"é€šè¿‡: {passed} ä¸ª")
    print(f"å¤±è´¥: {failed} ä¸ª")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼PyTorchæ¨¡å‹ç»“æ„å¼€å‘å®Œæˆã€‚")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä»£ç ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
