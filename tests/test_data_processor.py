#!/usr/bin/env python3
"""
æ•°æ®é¢„å¤„ç†æ¨¡å—æµ‹è¯•è„šæœ¬
æµ‹è¯•å¥åº·æ•°æ®é¢„å¤„ç†ç®¡é“çš„å„ä¸ªåŠŸèƒ½
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from models.data_processor import (
        HealthDataConfig,
        HealthDataCleaner,
        HealthFeatureEngineer,
        HealthDataNormalizer,
        HealthDataPipeline
    )
    print("âœ… æ•°æ®é¢„å¤„ç†æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def generate_sample_data(n_samples: int = 100) -> pd.DataFrame:
    """ç”Ÿæˆæ ·æœ¬å¥åº·æ•°æ®"""
    np.random.seed(42)
    
    data = {
        'patient_id': range(1, n_samples + 1),
        'age': np.random.randint(18, 80, n_samples),
        'gender': np.random.choice(['M', 'F', 'ç”·', 'å¥³'], n_samples),
        'systolic_pressure': np.random.normal(125, 15, n_samples),
        'diastolic_pressure': np.random.normal(80, 10, n_samples),
        'blood_sugar': np.random.normal(5.5, 1.2, n_samples),
        'weight': np.random.normal(70, 15, n_samples),
        'height': np.random.normal(165, 10, n_samples),
        'heart_rate': np.random.normal(75, 12, n_samples),
        'body_temperature': np.random.normal(36.5, 0.3, n_samples),
        'exercise_frequency': np.random.randint(0, 7, n_samples),
        'smoking_status': np.random.choice(['ä»ä¸', 'å¶å°”', 'ç»å¸¸', 'å·²æˆ’'], n_samples),
        'drinking_status': np.random.choice(['ä»ä¸', 'å¶å°”', 'ç»å¸¸', 'å·²æˆ’'], n_samples),
        'created_at': [datetime.now() - timedelta(days=np.random.randint(0, 365)) for _ in range(n_samples)]
    }
    
    df = pd.DataFrame(data)
    
    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
    df.loc[df.sample(frac=0.1).index, 'blood_sugar'] = np.nan
    df.loc[df.sample(frac=0.05).index, 'weight'] = np.nan
    df.loc[df.sample(frac=0.02).index, 'systolic_pressure'] = 999  # å¼‚å¸¸å€¼
    df.loc[df.sample(frac=0.03).index, 'heart_rate'] = 300  # å¼‚å¸¸å€¼
    
    return df

def test_config():
    """æµ‹è¯•é…ç½®ç±»"""
    print("\nâš™ï¸ æµ‹è¯•æ•°æ®é…ç½®...")
    
    config = HealthDataConfig()
    
    # æ£€æŸ¥é…ç½®é¡¹
    config_items = [
        ('è¡€å‹èŒƒå›´', config.BLOOD_PRESSURE_RANGE),
        ('è¡€ç³–èŒƒå›´', config.BLOOD_SUGAR_RANGE),
        ('BMIèŒƒå›´', config.BMI_RANGE),
        ('å¿ƒç‡èŒƒå›´', config.HEART_RATE_RANGE),
        ('ä½“æ¸©èŒƒå›´', config.TEMPERATURE_RANGE),
        ('æ€§åˆ«æ˜ å°„', config.GENDER_MAPPING),
        ('ç‰¹å¾æƒé‡', config.FEATURE_WEIGHTS)
    ]
    
    for name, item in config_items:
        print(f"  âœ… {name}: {item}")
    
    print("  âœ… é…ç½®ç±»æµ‹è¯•é€šè¿‡")

def test_data_cleaner():
    """æµ‹è¯•æ•°æ®æ¸…æ´—å™¨"""
    print("\nğŸ§¹ æµ‹è¯•æ•°æ®æ¸…æ´—å™¨...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    df = generate_sample_data(50)
    print(f"  åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    
    cleaner = HealthDataCleaner()
    
    # æµ‹è¯•æ•°å€¼æ•°æ®æ¸…æ´—
    df_cleaned = cleaner.clean_numerical_data(df)
    
    # æ£€æŸ¥å¼‚å¸¸å€¼æ˜¯å¦è¢«å¤„ç†
    sys_pressure_valid = df_cleaned['systolic_pressure'].between(70, 200).all()
    heart_rate_valid = df_cleaned['heart_rate'].between(30, 220).all()
    
    print(f"  âœ… è¡€å‹èŒƒå›´æ£€æŸ¥: {'é€šè¿‡' if sys_pressure_valid else 'å¤±è´¥'}")
    print(f"  âœ… å¿ƒç‡èŒƒå›´æ£€æŸ¥: {'é€šè¿‡' if heart_rate_valid else 'å¤±è´¥'}")
    
    # æµ‹è¯•åˆ†ç±»æ•°æ®æ¸…æ´—
    df_cleaned = cleaner.clean_categorical_data(df_cleaned)
    gender_mapped = df_cleaned['gender'].isin([0, 1]).all()
    print(f"  âœ… æ€§åˆ«æ˜ å°„æ£€æŸ¥: {'é€šè¿‡' if gender_mapped else 'å¤±è´¥'}")
    
    # æµ‹è¯•å¼‚å¸¸å€¼ç§»é™¤
    df_no_outliers = cleaner.remove_outliers(df_cleaned, method='iqr')
    print(f"  âœ… å¼‚å¸¸å€¼ç§»é™¤åå½¢çŠ¶: {df_no_outliers.shape}")
    
    return df_no_outliers

def test_feature_engineer():
    """æµ‹è¯•ç‰¹å¾å·¥ç¨‹å™¨"""
    print("\nğŸ”§ æµ‹è¯•ç‰¹å¾å·¥ç¨‹å™¨...")
    
    # ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®
    df_cleaned = test_data_cleaner()
    
    engineer = HealthFeatureEngineer()
    
    # æµ‹è¯•æ´¾ç”Ÿç‰¹å¾åˆ›å»º
    df_enhanced = engineer.create_derived_features(df_cleaned)
    
    # æ£€æŸ¥æ–°å¢ç‰¹å¾
    new_features = [
        'pulse_pressure', 'mean_arterial_pressure', 'hypertension_risk',
        'bmi', 'bmi_category', 'obesity_risk', 'age_group', 'senior_risk', 'health_score'
    ]
    
    created_features = []
    missing_features = []
    
    for feature in new_features:
        if feature in df_enhanced.columns:
            created_features.append(feature)
        else:
            missing_features.append(feature)
    
    print(f"  âœ… æˆåŠŸåˆ›å»ºç‰¹å¾ ({len(created_features)}): {created_features}")
    if missing_features:
        print(f"  âš ï¸ æœªåˆ›å»ºç‰¹å¾ ({len(missing_features)}): {missing_features}")
    
    # æµ‹è¯•æ—¶é—´ç‰¹å¾åˆ›å»º
    df_with_time = engineer.create_time_features(df_enhanced, 'created_at')
    time_features = ['year', 'month', 'day', 'weekday', 'hour', 'season']
    time_features_created = [f for f in time_features if f in df_with_time.columns]
    
    print(f"  âœ… æ—¶é—´ç‰¹å¾åˆ›å»º ({len(time_features_created)}): {time_features_created}")
    
    # æ£€æŸ¥å¥åº·è¯„åˆ†èŒƒå›´
    health_scores = df_enhanced['health_score']
    score_valid = health_scores.between(0, 100).all()
    print(f"  âœ… å¥åº·è¯„åˆ†èŒƒå›´æ£€æŸ¥: {'é€šè¿‡' if score_valid else 'å¤±è´¥'} (èŒƒå›´: {health_scores.min():.1f}-{health_scores.max():.1f})")
    
    return df_with_time

def test_data_normalizer():
    """æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–å™¨"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–å™¨...")
    
    # ä½¿ç”¨ç‰¹å¾å·¥ç¨‹åçš„æ•°æ®
    df_features = test_feature_engineer()
    
    normalizer = HealthDataNormalizer()
    
    # è®­ç»ƒæ ‡å‡†åŒ–å™¨
    df_normalized = normalizer.fit_transform(df_features)
    
    # æ£€æŸ¥æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–
    numerical_cols = df_normalized.select_dtypes(include=[np.number]).columns
    
    # æ£€æŸ¥æ ‡å‡†åŒ–æ•ˆæœï¼ˆå‡å€¼æ¥è¿‘0ï¼Œæ ‡å‡†å·®æ¥è¿‘1ï¼‰
    standardization_results = []
    for col in numerical_cols:
        mean_val = df_normalized[col].mean()
        std_val = df_normalized[col].std()
        is_standardized = abs(mean_val) < 0.1 and abs(std_val - 1) < 0.1
        standardization_results.append((col, is_standardized, mean_val, std_val))
    
    standardized_count = sum(1 for _, is_std, _, _ in standardization_results if is_std)
    print(f"  âœ… æ ‡å‡†åŒ–ç‰¹å¾æ•°é‡: {standardized_count}/{len(numerical_cols)}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†æ ‡å‡†åŒ–ç»“æœ
    for col, is_std, mean, std in standardization_results[:5]:
        status = "âœ…" if is_std else "âš ï¸"
        print(f"    {status} {col}: mean={mean:.3f}, std={std:.3f}")
    
    # æµ‹è¯•ç¼ºå¤±å€¼å¤„ç†
    df_with_missing = df_features.copy()
    df_with_missing.loc[:10, 'systolic_pressure'] = np.nan
    
    df_imputed = normalizer.handle_missing_values(df_with_missing, strategy='knn')
    missing_after = df_imputed.isnull().sum().sum()
    
    print(f"  âœ… ç¼ºå¤±å€¼å¤„ç†: å¤„ç†åå‰©ä½™ç¼ºå¤±å€¼ {missing_after} ä¸ª")
    
    return df_normalized

def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´æ•°æ®é¢„å¤„ç†ç®¡é“"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´é¢„å¤„ç†ç®¡é“...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    df_raw = generate_sample_data(200)
    print(f"  åŸå§‹æ•°æ®: {df_raw.shape}")
    
    # åˆå§‹åŒ–ç®¡é“
    pipeline = HealthDataPipeline()
    
    try:
        # å¤„ç†æ•°æ®
        df_processed, stats = pipeline.process(df_raw, training_mode=True)
        
        print(f"  âœ… å¤„ç†åæ•°æ®: {df_processed.shape}")
        print(f"  âœ… å¤„ç†è€—æ—¶: {stats['total_time']:.3f} ç§’")
        print(f"  âœ… å®Œæˆæ­¥éª¤: {len(stats['steps_completed'])}")
        
        # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
        print("\n  ğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        for step, time_cost in stats['processing_time'].items():
            print(f"    - {step}: {time_cost:.3f}ç§’")
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        quality = stats.get('data_quality', {})
        if quality:
            missing_total = sum(quality['missing_values'].values())
            print(f"  âœ… æ•°æ®è´¨é‡: ç¼ºå¤±å€¼ {missing_total} ä¸ª, é‡å¤è¡Œ {quality['duplicate_rows']} è¡Œ")
        
        return df_processed, stats
        
    except Exception as e:
        print(f"  âŒ ç®¡é“å¤„ç†å¤±è´¥: {e}")
        return None, None

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("\nâš¡ æ€§èƒ½æµ‹è¯•...")
    
    # ä¸åŒè§„æ¨¡æ•°æ®æµ‹è¯•
    test_sizes = [100, 500, 1000, 2000]
    pipeline = HealthDataPipeline()
    
    results = []
    
    for size in test_sizes:
        print(f"\n  æµ‹è¯•æ•°æ®è§„æ¨¡: {size} æ¡è®°å½•")
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        df = generate_sample_data(size)
        
        # è®¡æ—¶å¤„ç†
        start_time = datetime.now()
        try:
            df_processed, stats = pipeline.process(df, training_mode=True)
            end_time = datetime.now()
            
            duration = (end_time - start_time).total_seconds()
            records_per_second = size / duration if duration > 0 else 0
            
            results.append({
                'size': size,
                'duration': duration,
                'records_per_second': records_per_second,
                'final_features': df_processed.shape[1] if df_processed is not None else 0
            })
            
            print(f"    âœ… è€—æ—¶: {duration:.3f}ç§’, å¤„ç†é€Ÿåº¦: {records_per_second:.0f} è®°å½•/ç§’")
            print(f"    âœ… ç‰¹å¾æ•°é‡: {df_processed.shape[1] if df_processed is not None else 0}")
            
        except Exception as e:
            print(f"    âŒ å¤„ç†å¤±è´¥: {e}")
            results.append({
                'size': size,
                'duration': 0,
                'records_per_second': 0,
                'final_features': 0,
                'error': str(e)
            })
    
    # æ€§èƒ½æ‘˜è¦
    print(f"\n  ğŸ“Š æ€§èƒ½æ‘˜è¦:")
    successful_results = [r for r in results if r['records_per_second'] > 0]
    if successful_results:
        avg_speed = np.mean([r['records_per_second'] for r in successful_results])
        print(f"    å¹³å‡å¤„ç†é€Ÿåº¦: {avg_speed:.0f} è®°å½•/ç§’")
        print(f"    æœ€å¤§å¤„ç†è§„æ¨¡: {max(r['size'] for r in successful_results)} æ¡è®°å½•")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª SHEC AI æ•°æ®é¢„å¤„ç†æ¨¡å—æµ‹è¯•")
    print("=" * 60)
    
    try:
        # å„ä¸ªç»„ä»¶æµ‹è¯•
        test_config()
        # test_data_cleaner()  # åŒ…å«åœ¨ç‰¹å¾å·¥ç¨‹æµ‹è¯•ä¸­
        # test_feature_engineer()  # åŒ…å«åœ¨æ ‡å‡†åŒ–æµ‹è¯•ä¸­
        # test_data_normalizer()  # åŒ…å«åœ¨ç®¡é“æµ‹è¯•ä¸­
        test_full_pipeline()
        test_performance()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ•°æ®é¢„å¤„ç†æ¨¡å—æµ‹è¯•å®Œæˆï¼")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\nğŸ“‹ åŠŸèƒ½æ”¯æŒæ¸…å•:")
        features = [
            "âœ… æ•°æ®æ¸…æ´— (å¼‚å¸¸å€¼å¤„ç†ã€èŒƒå›´é™åˆ¶)",
            "âœ… ç‰¹å¾å·¥ç¨‹ (æ´¾ç”Ÿç‰¹å¾ã€æ—¶é—´ç‰¹å¾ã€å¥åº·è¯„åˆ†)",
            "âœ… æ•°æ®æ ‡å‡†åŒ– (Z-scoreæ ‡å‡†åŒ–ã€åˆ†ç±»ç¼–ç )",
            "âœ… ç¼ºå¤±å€¼å¤„ç† (KNNæ’è¡¥ã€ä¼—æ•°å¡«å……)",
            "âœ… å®Œæ•´ç®¡é“å¤„ç† (ç«¯åˆ°ç«¯æ•°æ®é¢„å¤„ç†)",
            "âœ… æ€§èƒ½ä¼˜åŒ– (æ”¯æŒå¤§è§„æ¨¡æ•°æ®å¤„ç†)",
            "âœ… è´¨é‡ç›‘æ§ (æ•°æ®è´¨é‡ç»Ÿè®¡å’ŒéªŒè¯)"
        ]
        
        for feature in features:
            print(f"  {feature}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
