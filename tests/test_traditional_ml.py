# ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹æµ‹è¯•è„šæœ¬
# æµ‹è¯•LightGBMã€XGBoostã€éšæœºæ£®æ—ç­‰ä¼ ç»ŸMLæ¨¡å‹

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
from sklearn.datasets import make_classification, make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

from models.traditional_ml import (
    create_health_ml_model, 
    create_ensemble_model,
    LightGBMHealthModel,
    XGBoostHealthModel,
    RandomForestHealthModel,
    EnsembleHealthModel
)
from utils.logger import get_logger

logger = get_logger(__name__)

def generate_health_data(task_type='classification', n_samples=1000, n_features=20):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿå¥åº·æ•°æ®
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ('classification' æˆ– 'regression')
        n_samples: æ ·æœ¬æ•°é‡
        n_features: ç‰¹å¾æ•°é‡
        
    Returns:
        X, y: ç‰¹å¾å’Œæ ‡ç­¾
    """
    if task_type == 'classification':
        # ç”Ÿæˆåˆ†ç±»æ•°æ®ï¼ˆå¥åº·é£é™©ç­‰çº§ï¼š0-ä½é£é™©ï¼Œ1-ä¸­é£é™©ï¼Œ2-é«˜é£é™©ï¼‰
        X, y = make_classification(
            n_samples=n_samples,
            n_features=n_features,
            n_informative=n_features//2,
            n_redundant=n_features//4,
            n_classes=3,
            n_clusters_per_class=1,
            random_state=42
        )
        
        # æ¨¡æ‹Ÿå¥åº·ç‰¹å¾åç§°
        feature_names = [
            'å¹´é¾„', 'æ€§åˆ«', 'èº«é«˜', 'ä½“é‡', 'BMI', 'æ”¶ç¼©å‹', 'èˆ’å¼ å‹', 'å¿ƒç‡',
            'è¡€ç³–', 'èƒ†å›ºé†‡', 'ç”˜æ²¹ä¸‰é…¯', 'ç™½ç»†èƒ', 'çº¢ç»†èƒ', 'è¡€å°æ¿',
            'å¸çƒŸå²', 'é¥®é…’å²', 'è¿åŠ¨é¢‘ç‡', 'ç¡çœ è´¨é‡', 'å‹åŠ›æ°´å¹³', 'å®¶æ—ç—…å²'
        ][:n_features]
        
        X_df = pd.DataFrame(X, columns=feature_names)
        y_labels = ['ä½é£é™©', 'ä¸­é£é™©', 'é«˜é£é™©']
        
        return X_df, y, y_labels
    
    else:
        # ç”Ÿæˆå›å½’æ•°æ®ï¼ˆå¥åº·è¯„åˆ†ï¼š0-100ï¼‰
        X, y = make_regression(
            n_samples=n_samples,
            n_features=n_features,
            n_informative=n_features//2,
            noise=0.1,
            random_state=42
        )
        
        # å°†yæ ‡å‡†åŒ–åˆ°0-100èŒƒå›´
        y = (y - y.min()) / (y.max() - y.min()) * 100
        
        feature_names = [
            'å¹´é¾„', 'æ€§åˆ«', 'èº«é«˜', 'ä½“é‡', 'BMI', 'æ”¶ç¼©å‹', 'èˆ’å¼ å‹', 'å¿ƒç‡',
            'è¡€ç³–', 'èƒ†å›ºé†‡', 'ç”˜æ²¹ä¸‰é…¯', 'ç™½ç»†èƒ', 'çº¢ç»†èƒ', 'è¡€å°æ¿',
            'å¸çƒŸå²', 'é¥®é…’å²', 'è¿åŠ¨é¢‘ç‡', 'ç¡çœ è´¨é‡', 'å‹åŠ›æ°´å¹³', 'å®¶æ—ç—…å²'
        ][:n_features]
        
        X_df = pd.DataFrame(X, columns=feature_names)
        
        return X_df, y, None

def test_lightgbm_model():
    """æµ‹è¯•LightGBMæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• LightGBM æ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆåˆ†ç±»æ•°æ®
        X, y, y_labels = generate_health_data('classification', 1000, 15)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}")
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {X_test.shape}")
        print(f"ç±»åˆ«åˆ†å¸ƒ: {np.bincount(y_train)}")
        
        # åˆ›å»ºLightGBMåˆ†ç±»æ¨¡å‹
        lgb_model = create_health_ml_model('lightgbm', 'classification', n_estimators=100)
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {lgb_model.model_name}")
        
        # è®­ç»ƒæ¨¡å‹
        lgb_model.fit(X_train, y_train)
        print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # é¢„æµ‹
        y_pred = lgb_model.predict(X_test)
        y_proba = lgb_model.predict_proba(X_test)
        
        print(f"âœ“ é¢„æµ‹å®Œæˆï¼Œé¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
        print(f"âœ“ æ¦‚ç‡é¢„æµ‹å½¢çŠ¶: {y_proba.shape}")
        
        # è¯„ä¼°
        metrics = lgb_model.evaluate(X_test, y_test)
        print("âœ“ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        for metric, value in metrics.items():
            print(f"  - {metric}: {value:.4f}")
        
        # ç‰¹å¾é‡è¦æ€§
        importance = lgb_model.get_feature_importance()
        if importance is not None:
            print(f"âœ“ ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼Œå½¢çŠ¶: {importance.shape}")
            top_features = np.argsort(importance)[-5:][::-1]
            print("  - Top 5 é‡è¦ç‰¹å¾:")
            for i, idx in enumerate(top_features):
                print(f"    {i+1}. {X.columns[idx]}: {importance[idx]:.4f}")
        
        # æµ‹è¯•å›å½’æ¨¡å‹
        print("\n--- æµ‹è¯•LightGBMå›å½’æ¨¡å‹ ---")
        X_reg, y_reg, _ = generate_health_data('regression', 800, 12)
        X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)
        
        lgb_reg_model = create_health_ml_model('lightgbm', 'regression', n_estimators=100)
        lgb_reg_model.fit(X_train_reg, y_train_reg)
        
        reg_metrics = lgb_reg_model.evaluate(X_test_reg, y_test_reg)
        print("âœ“ å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ:")
        for metric, value in reg_metrics.items():
            print(f"  - {metric}: {value:.4f}")
        
        print("âœ“ LightGBM æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— LightGBM æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_xgboost_model():
    """æµ‹è¯•XGBoostæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• XGBoost æ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆæ•°æ®
        X, y, y_labels = generate_health_data('classification', 800, 18)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}")
        
        # åˆ›å»ºXGBoostæ¨¡å‹
        xgb_model = create_health_ml_model('xgboost', 'classification', 
                                          n_estimators=100, max_depth=4, learning_rate=0.1)
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {xgb_model.model_name}")
        
        # è®­ç»ƒæ¨¡å‹
        xgb_model.fit(X_train, y_train, feature_selection=True, n_features=10)
        print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # é¢„æµ‹å’Œè¯„ä¼°
        metrics = xgb_model.evaluate(X_test, y_test)
        print("âœ“ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        for metric, value in metrics.items():
            print(f"  - {metric}: {value:.4f}")
        
        # ç‰¹å¾é‡è¦æ€§
        importance = xgb_model.get_feature_importance()
        if importance is not None:
            print(f"âœ“ ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆ")
        
        print("âœ“ XGBoost æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— XGBoost æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_random_forest_model():
    """æµ‹è¯•éšæœºæ£®æ—æ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• éšæœºæ£®æ— æ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆæ•°æ®
        X, y, y_labels = generate_health_data('classification', 600, 16)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # åˆ›å»ºéšæœºæ£®æ—æ¨¡å‹
        rf_model = create_health_ml_model('random_forest', 'classification', 
                                         n_estimators=50, max_depth=8)
        
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ: {rf_model.model_name}")
        
        # è®­ç»ƒæ¨¡å‹
        rf_model.fit(X_train, y_train)
        print("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # è¯„ä¼°
        metrics = rf_model.evaluate(X_test, y_test)
        print("âœ“ æ¨¡å‹è¯„ä¼°ç»“æœ:")
        for metric, value in metrics.items():
            print(f"  - {metric}: {value:.4f}")
        
        print("âœ“ éšæœºæ£®æ— æ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— éšæœºæ£®æ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_other_models():
    """æµ‹è¯•å…¶ä»–ä¼ ç»ŸMLæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• å…¶ä»–ä¼ ç»ŸMLæ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆå°æ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•
        X, y, y_labels = generate_health_data('classification', 400, 10)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # æµ‹è¯•å„ç§æ¨¡å‹
        model_configs = [
            ('logistic_regression', {}),
            ('svm', {'C': 1.0, 'kernel': 'rbf'}),
            ('gradient_boosting', {'n_estimators': 50}),
            ('knn', {'n_neighbors': 5}),
            ('naive_bayes', {})
        ]
        
        results = {}
        
        for model_name, params in model_configs:
            try:
                model = create_health_ml_model(model_name, 'classification', **params)
                model.fit(X_train, y_train, feature_selection=False)  # å…³é—­ç‰¹å¾é€‰æ‹©åŠ é€Ÿè®­ç»ƒ
                
                metrics = model.evaluate(X_test, y_test)
                results[model_name] = metrics['accuracy']
                
                print(f"âœ“ {model.model_name}: å‡†ç¡®ç‡ {metrics['accuracy']:.4f}")
                
            except Exception as e:
                print(f"âœ— {model_name} æµ‹è¯•å¤±è´¥: {e}")
                results[model_name] = 0.0
        
        print("\nâœ“ æ¨¡å‹æ€§èƒ½å¯¹æ¯”:")
        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
        for model_name, accuracy in sorted_results:
            print(f"  - {model_name}: {accuracy:.4f}")
        
        print("âœ“ å…¶ä»–ä¼ ç»ŸMLæ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— å…¶ä»–ä¼ ç»ŸMLæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_ensemble_model():
    """æµ‹è¯•é›†æˆæ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯• é›†æˆæ¨¡å‹")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆæ•°æ®
        X, y, y_labels = generate_health_data('classification', 800, 15)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}")
        
        # é…ç½®å¤šä¸ªåŸºç¡€æ¨¡å‹
        model_configs = [
            {'name': 'lightgbm', 'params': {'n_estimators': 50}},
            {'name': 'xgboost', 'params': {'n_estimators': 50, 'max_depth': 4}},
            {'name': 'random_forest', 'params': {'n_estimators': 30}},
            {'name': 'gradient_boosting', 'params': {'n_estimators': 30}}
        ]
        
        # åˆ›å»ºé›†æˆæ¨¡å‹
        ensemble_model = create_ensemble_model(
            model_configs, 
            model_type='classification',
            voting='soft',
            weights=[0.3, 0.3, 0.2, 0.2]
        )
        
        print(f"âœ“ é›†æˆæ¨¡å‹åˆ›å»ºæˆåŠŸ: {ensemble_model.model_name}")
        print(f"âœ“ åŒ…å« {len(ensemble_model.base_models)} ä¸ªåŸºç¡€æ¨¡å‹")
        
        # è®­ç»ƒé›†æˆæ¨¡å‹
        ensemble_model.fit(X_train, y_train, feature_selection=True, n_features=10)
        print("âœ“ é›†æˆæ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # è¯„ä¼°é›†æˆæ¨¡å‹
        ensemble_metrics = ensemble_model.evaluate(X_test, y_test)
        print("âœ“ é›†æˆæ¨¡å‹è¯„ä¼°ç»“æœ:")
        for metric, value in ensemble_metrics.items():
            print(f"  - {metric}: {value:.4f}")
        
        # ä¸å•ä¸ªæ¨¡å‹å¯¹æ¯”
        print("\n--- ä¸å•ä¸ªæ¨¡å‹æ€§èƒ½å¯¹æ¯” ---")
        
        # æµ‹è¯•å•ä¸ªLightGBMæ¨¡å‹
        single_lgb = create_health_ml_model('lightgbm', 'classification', n_estimators=100)
        single_lgb.fit(X_train, y_train, feature_selection=True, n_features=10)
        lgb_metrics = single_lgb.evaluate(X_test, y_test)
        
        print(f"âœ“ å•ä¸ªLightGBMå‡†ç¡®ç‡: {lgb_metrics['accuracy']:.4f}")
        print(f"âœ“ é›†æˆæ¨¡å‹å‡†ç¡®ç‡: {ensemble_metrics['accuracy']:.4f}")
        
        improvement = ensemble_metrics['accuracy'] - lgb_metrics['accuracy']
        print(f"âœ“ æ€§èƒ½æå‡: {improvement:.4f} ({improvement*100:.2f}%)")
        
        # æµ‹è¯•æ¦‚ç‡é¢„æµ‹
        ensemble_proba = ensemble_model.predict_proba(X_test[:5])
        print(f"âœ“ é›†æˆæ¦‚ç‡é¢„æµ‹å½¢çŠ¶: {ensemble_proba.shape}")
        
        print("âœ“ é›†æˆæ¨¡å‹æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— é›†æˆæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_model_persistence():
    """æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½"""
    print("=" * 60)
    print("æµ‹è¯• æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
    print("=" * 60)
    
    try:
        # ç”Ÿæˆæ•°æ®
        X, y, _ = generate_health_data('classification', 500, 12)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # è®­ç»ƒæ¨¡å‹
        model = create_health_ml_model('lightgbm', 'classification', n_estimators=50)
        model.fit(X_train, y_train)
        
        # ä¿å­˜æ¨¡å‹
        model_path = "test_traditional_ml_model.joblib"
        model.save_model(model_path)
        print(f"âœ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # è·å–åŸå§‹é¢„æµ‹
        original_pred = model.predict(X_test)
        
        # åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹å¹¶åŠ è½½
        new_model = create_health_ml_model('lightgbm', 'classification')
        new_model.load_model(model_path)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•åŠ è½½çš„æ¨¡å‹
        loaded_pred = new_model.predict(X_test)
        
        # éªŒè¯é¢„æµ‹ç»“æœä¸€è‡´æ€§
        pred_match = np.array_equal(original_pred, loaded_pred)
        print(f"âœ“ é¢„æµ‹ç»“æœä¸€è‡´æ€§: {pred_match}")
        
        if pred_match:
            print("âœ“ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½æ­£å¸¸")
        else:
            print("âœ— æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ç»“æœä¸ä¸€è‡´")
            return False
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(model_path):
            os.remove(model_path)
            print("âœ“ æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†")
        
        print("âœ“ æ¨¡å‹æŒä¹…åŒ–æµ‹è¯•é€šè¿‡\n")
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹æŒä¹…åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """è¿è¡Œæ‰€æœ‰ä¼ ç»ŸMLæ¨¡å‹æµ‹è¯•"""
    print("å¼€å§‹ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹é›†æˆæµ‹è¯•")
    print("=" * 80)
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("LightGBMæ¨¡å‹", test_lightgbm_model),
        ("XGBoostæ¨¡å‹", test_xgboost_model),
        ("éšæœºæ£®æ—æ¨¡å‹", test_random_forest_model),
        ("å…¶ä»–ä¼ ç»ŸMLæ¨¡å‹", test_other_models),
        ("é›†æˆæ¨¡å‹", test_ensemble_model),
        ("æ¨¡å‹æŒä¹…åŒ–", test_model_persistence),
    ]
    
    for test_name, test_func in tests:
        print(f"\nå¼€å§‹æµ‹è¯•: {test_name}")
        result = test_func()
        test_results.append((test_name, result))
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n" + "=" * 80)
    print("ä¼ ç»ŸMLæ¨¡å‹æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "é€šè¿‡" if result else "å¤±è´¥"
        symbol = "âœ“" if result else "âœ—"
        print(f"{symbol} {test_name}: {status}")
        
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\næ€»è®¡: {passed + failed} ä¸ªæµ‹è¯•")
    print(f"é€šè¿‡: {passed} ä¸ª")
    print(f"å¤±è´¥: {failed} ä¸ª")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼ä¼ ç»ŸMLæ¨¡å‹é›†æˆå®Œæˆã€‚")
        print("\nğŸ“Š æ”¯æŒçš„æ¨¡å‹ç±»å‹:")
        print("- LightGBM (åˆ†ç±»/å›å½’)")
        print("- XGBoost (åˆ†ç±»/å›å½’)")
        print("- éšæœºæ£®æ— (åˆ†ç±»/å›å½’)")
        print("- é€»è¾‘å›å½’/çº¿æ€§å›å½’")
        print("- æ”¯æŒå‘é‡æœº (SVM)")
        print("- æ¢¯åº¦æå‡")
        print("- Kè¿‘é‚» (KNN)")
        print("- æœ´ç´ è´å¶æ–¯")
        print("- é›†æˆæ¨¡å‹ (å¤šæ¨¡å‹èåˆ)")
        
        print("\nğŸš€ ä¸»è¦åŠŸèƒ½:")
        print("- è‡ªåŠ¨ç‰¹å¾é¢„å¤„ç†å’Œé€‰æ‹©")
        print("- æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹")
        print("- æ€§èƒ½è¯„ä¼°å’Œç‰¹å¾é‡è¦æ€§åˆ†æ")
        print("- æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
        print("- å¤šæ¨¡å‹é›†æˆå’ŒæŠ•ç¥¨")
        
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä»£ç ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
